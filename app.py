import streamlit as st
import numpy as np
import pandas as pd
import re
import math
import requests
import joblib
import os
import socket
from urllib.parse import urlparse
from sklearn.ensemble import RandomForestClassifier
from requests.exceptions import RequestException, Timeout, ConnectionError, SSLError, TooManyRedirects

try:
    import idna
    IDNA_AVAILABLE = True
except ImportError:
    IDNA_AVAILABLE = False

st.set_page_config(
    page_title="CyberShield AI | Phishing Detector",
    page_icon="üõ°Ô∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.markdown("""
<style>
    /* –û—Å–Ω–æ–≤–Ω–æ–π —Ñ–æ–Ω –∏ —à—Ä–∏—Ñ—Ç—ã */
    .stApp {
        background-color: #0e1117;
    }
    
    /* –°—Ç–∏–ª–∏–∑–∞—Ü–∏—è –∑–∞–≥–æ–ª–æ–≤–∫–∞ */
    h1 {
        color: #00ff41;
        font-family: 'Courier New', Courier, monospace;
        text-shadow: 0 0 10px #00ff41;
    }
    
    /* –ö–∞—Ä—Ç–æ—á–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ */
    .result-card {
        padding: 30px;
        border-radius: 15px;
        margin-top: 20px;
        text-align: center;
        box-shadow: 0 8px 16px rgba(0, 0, 0, 0.4);
        backdrop-filter: blur(10px);
    }
    
    .safe {
        background-color: rgba(46, 204, 113, 0.2);
        border: 2px solid #2ecc71;
        color: #2ecc71;
    }
    
    .danger {
        background-color: rgba(231, 76, 60, 0.2);
        border: 2px solid #e74c3c;
        color: #e74c3c;
        animation: pulse 2s infinite;
    }
    
    .suspicious {
        background-color: rgba(241, 196, 15, 0.2);
        border: 2px solid #f1c40f;
        color: #f1c40f;
    }

    @keyframes pulse {
        0% { box-shadow: 0 0 0 0 rgba(231, 76, 60, 0.4); }
        70% { box-shadow: 0 0 0 10px rgba(231, 76, 60, 0); }
        100% { box-shadow: 0 0 0 0 rgba(231, 76, 60, 0); }
    }
</style>
""", unsafe_allow_html=True)

def calculate_entropy(text):
    if not text:
        return 0
    entropy = 0
    for x in range(256):
        p_x = float(text.count(chr(x))) / len(text)
        if p_x > 0:
            entropy += - p_x * math.log(p_x, 2)
    return entropy

def is_known_legitimate_domain(hostname):
    if not hostname:
        return False
    
    hostname_lower = hostname.lower()
    known_domains = [
        'instagram.com', 'facebook.com', 'google.com', 'gmail.com', 'github.com', 
        'microsoft.com', 'apple.com', 'amazon.com', 'twitter.com',
        'linkedin.com', 'youtube.com', 'netflix.com', 'paypal.com',
        'telegram.org',
        'yandex.ru', 'ya.ru', 'mail.ru', 'rambler.ru', 'km.ru', 'qip.ru',
        'vk.com', 'ok.ru', 'livejournal.com', 'my.mail.ru',
        'ria.ru', 'tass.ru', 'kommersant.ru', 'iz.ru', 'rg.ru', 'lenta.ru',
        'gazeta.ru', 'rt.com', 'mk.ru', 'rbc.ru', 'vedomosti.ru', 'forbes.ru',
        'takiedela.ru', 'meduza.io', 'novayagazeta.ru', 'fontanka.ru', '74.ru',
        'baikal24.ru', 'chelob.ru', 'sibirrealty.ru',
        'rutube.ru', 'smotrim.ru', 'ivi.ru', 'kinopoisk.ru', 'more.tv',
        'start.ru', 'premier.ru', 'okko.tv', 'megogo.ru', 'amediateka.ru',
        'wildberries.ru', 'wildberries.com', 'ozon.ru', 'market.yandex.ru', 'aliexpress.ru',
        'citilink.ru', 'mvideo.ru', 'dns-shop.ru', 'eldorado.ru', 'lamoda.ru',
        'beru.ru', 'ulmart.ru', 'svyaznoy.ru', 'technopark.ru', 'obi.ru',
        'auchan.ru', 'lenta.com', 'magnit.ru', 'perekrestok.ru', '5ka.ru',
        'sberbank.ru', 'vtb.ru', 'alfabank.ru', 'tinkoff.ru', 'gazprombank.ru',
        'raiffeisen.ru', 'open.ru', 'sovcombank.ru', 'pochtabank.ru', 'rshb.ru',
        'mkb.ru', 'homecredit.ru', 'rsb.ru', 'yoomoney.ru', 'vbr.ru', 'tbank.ru',
        'gosuslugi.ru', 'nalog.ru', 'pfr.gov.ru', 'fss.ru', 'rosreestr.ru',
        'minzdrav.gov.ru', 'minobrnauki.gov.ru', 'economy.gov.ru',
        'uchi.ru', 'yaklass.ru', 'foxford.ru', 'gb.ru', 'netology.ru',
        'skillbox.ru', 'stepik.org', 'openedu.ru', 'lektorium.tv',
        'arzamas.academy', 'postnauka.ru', 'intuit.ru', 'universarium.org',
        'resh.edu.ru', 'mos.ru',
        'hh.ru', 'superjob.ru', 'rabota.ru', 'avito.ru', 'zarplata.ru',
        'trud.com', 'unity.ru', 'gorodrabot.ru', 'rabotamail.ru',
        'cian.ru', 'yard.ru', 'mirkvartir.ru', 'domclick.ru', 'ngs.ru',
        'etagi.com', 'youla.ru',
        'auto.ru', 'drom.ru', 'cars.ru', 'car.ru', 'zr.ru', 'autoreview.ru',
        'kolesa.ru', 'abw.by', 'mladsha.ru', 'avtopodbor.ru', 'autostat.ru',
        'autovesti.ru',
        'sberhealth.ru', 'napopravku.ru', 'prodoctorov.ru', 'medportal.ru',
        'stomatologii.ru', 'apteki.ru', 'eapteka.ru', 'health.mail.ru',
        'medicina.ru',
        'store.steampowered.com', 'kanobu.ru', 'stopgame.ru', 'igromania.ru',
        'gamexp.ru', 'gmbox.ru', 'ag.ru', 'playground.ru', 'riotgames.com',
        'worldoftanks.ru', 'worldofwarships.ru', 'cfire.mail.ru', 'warthunder.ru',
        'eda.ru', 'recepty.ru', 'povarenok.ru', 'gotovim-doma.ru', 'menu.ru',
        'delivery-club.ru', 'sbermarket.ru',
        'championat.com', 'sport-express.ru', 'sports.ru', 'matchtv.ru',
        'sportbox.ru', 'rfs.ru', 'fnl.ru', 'khl.ru', 'ffr.ru', 'volley.ru',
        'russiabasket.ru', 'tennis-russia.ru',
        'music.yandex.ru', 'zvuk.com', 'boom.ru', 'stereo.ru',
        'habr.com', '3dnews.ru', 'ixbt.com', 'cnews.ru', 'server.ru',
        'hosting.ru', 'reg.ru', 'nic.ru', 'timeweb.com', 'beget.com',
        'sprinthost.ru', 'firstvds.ru', 'selectel.ru', 'cloud.ru',
        'pikabu.ru', 'yaplakal.com', 'dirty.ru', 'fishki.net', 'beha.ru',
        'kp.ru', 'aif.ru', 'vm.ru', 'spbdnevnik.ru', 'nevnov.ru', '47news.ru',
        'gorod-plus.tv', 'online47.ru', 'lentv24.ru', 'moika78.ru', '78.ru',
        '5-tv.ru', 'saint-petersburg.ru', 'peterburg2.ru', 'spbinfo.ru',
        'karpovka.com', 'newkaliningrad.ru', 'klops.ru', 'kaliningrad.ru',
        'rugrad.eu', 'kgd.ru', 'drugoigorod.ru', 'samaratoday.ru',
        'progorodsamara.ru', 'volgnews.ru', 'sgpress.ru', '63.ru', 'niasamara.ru',
        'irr.ru', 'kufar.by', 'tut.by', 'onliner.by', '2gis.ru', 'nigma.ru',
        'sputnik.ru', 'gismeteo.ru'
    ]
    
    return any(
        hostname_lower == domain or 
        hostname_lower.endswith('.' + domain) or 
        (hostname_lower.endswith(domain) and (len(hostname_lower) == len(domain) or hostname_lower[-(len(domain)+1)] == '.'))
        for domain in known_domains
    )

def check_site_availability(url, timeout=5, is_known_domain=False):
    try:
        response = requests.head(url, timeout=timeout, allow_redirects=True, verify=False)
        if response.status_code == 405:
            response = requests.get(url, timeout=timeout, allow_redirects=True, verify=False, stream=True)
        
        if is_known_domain:
            return True, "–°–∞–π—Ç –¥–æ—Å—Ç—É–ø–µ–Ω", response.status_code
        
        if response.status_code >= 400:
            if response.status_code == 404:
                return True, "–°–∞–π—Ç –¥–æ—Å—Ç—É–ø–µ–Ω (—Å—Ç—Ä–∞–Ω–∏—Ü–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞)", response.status_code
            elif response.status_code == 403:
                return True, "–°–∞–π—Ç –¥–æ—Å—Ç—É–ø–µ–Ω (–¥–æ—Å—Ç—É–ø –æ–≥—Ä–∞–Ω–∏—á–µ–Ω)", response.status_code
            elif response.status_code in [418, 429]:
                return True, f"–°–∞–π—Ç –¥–æ—Å—Ç—É–ø–µ–Ω (–∫–æ–¥ {response.status_code})", response.status_code
            elif response.status_code in [503, 502, 504]:
                return True, f"–°–∞–π—Ç –¥–æ—Å—Ç—É–ø–µ–Ω (–≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∫–æ–¥ {response.status_code})", response.status_code
            elif response.status_code >= 500:
                return True, f"–°–∞–π—Ç –¥–æ—Å—Ç—É–ø–µ–Ω (–æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞ {response.status_code})", response.status_code
            else:
                return True, f"–°–∞–π—Ç –¥–æ—Å—Ç—É–ø–µ–Ω (–∫–æ–¥ {response.status_code})", response.status_code
        
        return True, "–°–∞–π—Ç –¥–æ—Å—Ç—É–ø–µ–Ω", response.status_code
    
    except Timeout:
        if is_known_domain:
            return True, "–°–∞–π—Ç –¥–æ—Å—Ç—É–ø–µ–Ω (—Ç–∞–π–º–∞—É—Ç –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ)", None
        return False, "–¢–∞–π–º–∞—É—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è - —Å–∞–π—Ç –Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç", None
    except ConnectionError as e:
        try:
            parsed = urlparse(url)
            hostname = parsed.netloc or parsed.path.split('/')[0]
            socket.gethostbyname(hostname)
            if is_known_domain:
                return True, "–°–∞–π—Ç –¥–æ—Å—Ç—É–ø–µ–Ω (–ø—Ä–æ–±–ª–µ–º–∞ —Å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ–º)", None
            return False, "–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ —Å–µ—Ä–≤–µ—Ä—É", None
        except socket.gaierror:
            return False, "–î–æ–º–µ–Ω –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç (DNS –æ—à–∏–±–∫–∞)", None
        except:
            if is_known_domain:
                return True, "–°–∞–π—Ç –¥–æ—Å—Ç—É–ø–µ–Ω (–æ—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è)", None
            return False, "–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è", None
    except SSLError:
        try:
            http_url = url.replace('https://', 'http://')
            response = requests.head(http_url, timeout=timeout, allow_redirects=True, verify=False)
            return True, "–°–∞–π—Ç –¥–æ—Å—Ç—É–ø–µ–Ω (HTTP, –±–µ–∑ SSL)", response.status_code
        except:
            if is_known_domain:
                return True, "–°–∞–π—Ç –¥–æ—Å—Ç—É–ø–µ–Ω (–ø—Ä–æ–±–ª–µ–º–∞ —Å SSL)", None
            return False, "–û—à–∏–±–∫–∞ SSL –∏ HTTP –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω", None
    except TooManyRedirects:
        return True, "–°–∞–π—Ç –¥–æ—Å—Ç—É–ø–µ–Ω (–º–Ω–æ–≥–æ —Ä–µ–¥–∏—Ä–µ–∫—Ç–æ–≤)", None
    except RequestException as e:
        if is_known_domain:
            return True, "–°–∞–π—Ç –¥–æ—Å—Ç—É–ø–µ–Ω (–æ—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞)", None
        return False, f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞: {str(e)[:50]}", None
    except Exception as e:
        if is_known_domain:
            return True, "–°–∞–π—Ç –¥–æ—Å—Ç—É–ø–µ–Ω", None
        return False, f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞: {str(e)[:50]}", None

def normalize_hostname(hostname):
    if not hostname:
        return hostname
    
    try:
        if hostname.startswith('xn--'):
            parts = hostname.split('.')
            normalized_parts = []
            for part in parts:
                if part.startswith('xn--'):
                    try:
                        if IDNA_AVAILABLE:
                            decoded = idna.decode(part.encode('ascii'))
                            normalized_parts.append(decoded)
                        else:
                            if part == 'xn--p1ai':
                                normalized_parts.append('—Ä—Ñ')
                            else:
                                normalized_parts.append(part)
                    except:
                        normalized_parts.append(part)
                else:
                    normalized_parts.append(part)
            return '.'.join(normalized_parts)
    except:
        pass
    
    return hostname

def extract_features(url):
    features = []
    
    if not re.match(r'^https?://', url):
        parse_url = 'http://' + url
    else:
        parse_url = url

    try:
        parsed = urlparse(parse_url)
        hostname = parsed.netloc
        path = parsed.path
    except:
        hostname = ""
        path = ""

    hostname_normalized = normalize_hostname(hostname)
    hostname_lower = hostname_normalized.lower() if hostname_normalized else ""
    path = path.lower() if path else ""

    ip_pattern = re.search(r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}', url)
    features.append(1 if ip_pattern else 0)
    
    features.append(1 if len(url) > 75 else 0)
    
    short_domains = ['bit.ly', 'tinyurl.com', 'goo.gl', 't.co', 'ow.ly', 'is.gd']
    is_short_url = any(short in hostname_lower for short in short_domains)
    features.append(1 if is_short_url else 0)
    
    features.append(1 if '@' in url else 0)
    
    if '://' in url:
        after_protocol = url.split('://', 1)[1]
        features.append(1 if '//' in after_protocol else 0)
    else:
        features.append(0)
    
    if hostname:
        has_prefix_suffix = hostname.startswith('-') or hostname.endswith('-')
        if not has_prefix_suffix:
            for part in hostname.split('.'):
                if part.startswith('-') or part.endswith('-'):
                    has_prefix_suffix = True
                    break
        features.append(1 if has_prefix_suffix else 0)
    else:
        features.append(0)
    
    if hostname:
        subdomain_count = hostname.count('.') - 1
        features.append(subdomain_count)
    else:
        features.append(0)
    
    features.append(1 if parsed.scheme == 'https' else 0)
    
    if hostname:
        domain_parts = hostname.split('.')
        if len(domain_parts) > 1:
            main_domain = '.'.join(domain_parts[:-1])
            domain_len = len(main_domain)
        else:
            domain_len = len(hostname)
        known_short_domains = ['ya.ru', 'go.com', 'tv', 'io', 'ai', 'me', 'co', 'cc']
        if any(short in hostname_lower for short in known_short_domains):
            features.append(max(domain_len, 4))
        else:
            features.append(domain_len)
    else:
        features.append(0)
    
    if hostname and ':' in hostname:
        try:
            port = int(hostname.split(':')[1])
            features.append(1 if port not in [80, 443, 8080] else 0)
        except:
            features.append(0)
    else:
        features.append(0)
    
    special_chars = ['%', '&', '=', '?', '#', '+']
    special_count = sum(url.count(char) for char in special_chars)
    features.append(1 if special_count > 3 else 0)
    
    features.append(calculate_entropy(hostname))
    
    suspicious_words = ['verify', 'update', 'secure', 'confirm', 'validate']
    path_suspicious = ['login', 'account', 'bank']
    
    known_domains = [
        'instagram.com', 'facebook.com', 'google.com', 'gmail.com', 'github.com', 
        'microsoft.com', 'apple.com', 'amazon.com', 'twitter.com',
        'linkedin.com', 'youtube.com', 'netflix.com', 'paypal.com',
        'telegram.org',
        'yandex.ru', 'ya.ru', 'mail.ru', 'rambler.ru', 'km.ru', 'qip.ru',
        'vk.com', 'ok.ru', 'livejournal.com', 'my.mail.ru',
        'ria.ru', 'tass.ru', 'kommersant.ru', 'iz.ru', 'rg.ru', 'lenta.ru',
        'gazeta.ru', 'rt.com', 'mk.ru', 'rbc.ru', 'vedomosti.ru', 'forbes.ru',
        'takiedela.ru', 'meduza.io', 'novayagazeta.ru', 'fontanka.ru', '74.ru',
        'baikal24.ru', 'chelob.ru', 'sibirrealty.ru',
        'rutube.ru', 'smotrim.ru', 'ivi.ru', 'kinopoisk.ru', 'more.tv',
        'start.ru', 'premier.ru', 'okko.tv', 'megogo.ru', 'amediateka.ru',
        'wildberries.ru', 'wildberries.com', 'ozon.ru', 'market.yandex.ru', 'aliexpress.ru',
        'citilink.ru', 'mvideo.ru', 'dns-shop.ru', 'eldorado.ru', 'lamoda.ru',
        'beru.ru', 'ulmart.ru', 'svyaznoy.ru', 'technopark.ru', 'obi.ru',
        'auchan.ru', 'lenta.com', 'magnit.ru', 'perekrestok.ru', '5ka.ru',
        'sberbank.ru', 'vtb.ru', 'alfabank.ru', 'tinkoff.ru', 'gazprombank.ru',
        'raiffeisen.ru', 'open.ru', 'sovcombank.ru', 'pochtabank.ru', 'rshb.ru',
        'mkb.ru', 'homecredit.ru', 'rsb.ru', 'yoomoney.ru', 'vbr.ru', 'tbank.ru',
        'gosuslugi.ru', 'nalog.ru', 'pfr.gov.ru', 'fss.ru', 'rosreestr.ru',
        'minzdrav.gov.ru', 'minobrnauki.gov.ru', 'economy.gov.ru',
        'uchi.ru', 'yaklass.ru', 'foxford.ru', 'gb.ru', 'netology.ru',
        'skillbox.ru', 'stepik.org', 'openedu.ru', 'lektorium.tv',
        'arzamas.academy', 'postnauka.ru', 'intuit.ru', 'universarium.org',
        'resh.edu.ru', 'mos.ru',
        'hh.ru', 'superjob.ru', 'rabota.ru', 'avito.ru', 'zarplata.ru',
        'trud.com', 'unity.ru', 'gorodrabot.ru', 'rabotamail.ru',
        'cian.ru', 'yard.ru', 'mirkvartir.ru', 'domclick.ru', 'ngs.ru',
        'etagi.com', 'youla.ru',
        'auto.ru', 'drom.ru', 'cars.ru', 'car.ru', 'zr.ru', 'autoreview.ru',
        'kolesa.ru', 'abw.by', 'mladsha.ru', 'avtopodbor.ru', 'autostat.ru',
        'autovesti.ru',
        'sberhealth.ru', 'napopravku.ru', 'prodoctorov.ru', 'medportal.ru',
        'stomatologii.ru', 'apteki.ru', 'eapteka.ru', 'health.mail.ru',
        'medicina.ru',
        'store.steampowered.com', 'kanobu.ru', 'stopgame.ru', 'igromania.ru',
        'gamexp.ru', 'gmbox.ru', 'ag.ru', 'playground.ru', 'riotgames.com',
        'worldoftanks.ru', 'worldofwarships.ru', 'cfire.mail.ru', 'warthunder.ru',
        'eda.ru', 'recepty.ru', 'povarenok.ru', 'gotovim-doma.ru', 'menu.ru',
        'delivery-club.ru', 'sbermarket.ru',
        'championat.com', 'sport-express.ru', 'sports.ru', 'matchtv.ru',
        'sportbox.ru', 'rfs.ru', 'fnl.ru', 'khl.ru', 'ffr.ru', 'volley.ru',
        'russiabasket.ru', 'tennis-russia.ru',
        'music.yandex.ru', 'zvuk.com', 'boom.ru', 'stereo.ru',
        'habr.com', '3dnews.ru', 'ixbt.com', 'cnews.ru', 'server.ru',
        'hosting.ru', 'reg.ru', 'nic.ru', 'timeweb.com', 'beget.com',
        'sprinthost.ru', 'firstvds.ru', 'selectel.ru', 'cloud.ru',
        'pikabu.ru', 'yaplakal.com', 'dirty.ru', 'fishki.net', 'beha.ru',
        'kp.ru', 'aif.ru', 'vm.ru', 'spbdnevnik.ru', 'nevnov.ru', '47news.ru',
        'gorod-plus.tv', 'online47.ru', 'lentv24.ru', 'moika78.ru', '78.ru',
        '5-tv.ru', 'saint-petersburg.ru', 'peterburg2.ru', 'spbinfo.ru',
        'karpovka.com', 'newkaliningrad.ru', 'klops.ru', 'kaliningrad.ru',
        'rugrad.eu', 'kgd.ru', 'drugoigorod.ru', 'samaratoday.ru',
        'progorodsamara.ru', 'volgnews.ru', 'sgpress.ru', '63.ru', 'niasamara.ru',
        'irr.ru', 'kufar.by', 'tut.by', 'onliner.by', '2gis.ru', 'nigma.ru',
        'sputnik.ru', 'yandex.ru', 'gismeteo.ru',
        '–µ–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥.—Ä—Ñ', '–º–æ—Å–∫–≤–∞.—Ä—Ñ', '—Å–ø–±.—Ä—Ñ', '—Å–∞–Ω–∫—Ç-–ø–µ—Ç–µ—Ä–±—É—Ä–≥.—Ä—Ñ',
        '—à–∫–æ–ª–∞.—Ä—Ñ', '–≥–∏–º–Ω–∞–∑–∏—è.—Ä—Ñ', '–ª–∏—Ü–µ–π.—Ä—Ñ',
        'edu.ru', 'school.edu.ru', 'gymnasium.edu.ru', 'lyceum.edu.ru'
    ]
    
    is_educational = False
    if hostname_lower:
        educational_tlds = ['.—Ä—Ñ', '.edu.ru', '.edu', '.school']
        if any(hostname_lower.endswith(tld) for tld in educational_tlds):
            is_educational = True
        
        educational_keywords = ['—à–∫–æ–ª–∞', '–≥–∏–º–Ω–∞–∑–∏—è', '–ª–∏—Ü–µ–π', '—É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç', '–∏–Ω—Å—Ç–∏—Ç—É—Ç', 
                               '–∫–æ–ª–ª–µ–¥–∂', '—É—á–∏–ª–∏—â–µ', 'school', 'gymnasium', 'lyceum', 
                               'university', 'college', 'edu', '–µ–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥', '–º–æ—Å–∫–≤–∞']
        if any(keyword in hostname_lower for keyword in educational_keywords):
            is_educational = True
    
    is_known_domain = any(
        hostname_lower == domain or 
        hostname_lower.endswith('.' + domain) or 
        (hostname_lower.endswith(domain) and (len(hostname_lower) == len(domain) or hostname_lower[-(len(domain)+1)] == '.'))
        for domain in known_domains
    )
    
    if is_educational:
        is_known_domain = True
    
    count_suspicious = sum(1 for word in suspicious_words if word in url.lower())
    
    if not is_known_domain:
        count_suspicious += sum(1 for word in path_suspicious if word in path and word not in hostname_lower)
    
    features.append(count_suspicious)
    features.append(1 if is_known_domain else 0)
    features.append(hostname.count('-') if hostname else 0)

    return features

@st.cache_resource
def load_and_train_model(use_csv=False):
    data = []
    labels = []
    total_loaded = 0
    
    if use_csv:
        csv_files = [
            ('malicious_phish.csv', 'type'),
            ('legitimate_dataset.csv', 'label'),
            ('dataset_example.csv', 'label')
        ]
        
        for csv_path, label_column in csv_files:
            try:
                if os.path.exists(csv_path):
                    df = pd.read_csv(csv_path)
                    
                    if 'url' not in df.columns:
                        st.warning(f"‚ö†Ô∏è –§–∞–π–ª {csv_path} –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–æ–ª–æ–Ω–∫—É 'url'. –ü—Ä–æ–ø—É—â–µ–Ω.")
                        continue
                    
                    file_count = 0
                    for _, row in df.iterrows():
                        url = str(row['url']).strip()
                        if not url or url == 'nan':
                            continue
                        
                        if label_column == 'type':
                            url_type = str(row['type']).strip().lower()
                            if url_type in ['phishing', 'defacement', 'malware']:
                                label = 1
                            elif url_type == 'benign':
                                label = 0
                            else:
                                continue
                        else:
                            label = int(row[label_column])
                        
                        data.append(extract_features(url))
                        labels.append(label)
                        file_count += 1
                    
                    total_loaded += file_count
                    st.info(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ {file_count:,} –∑–∞–ø–∏—Å–µ–π –∏–∑ {csv_path}")
                else:
                    st.warning(f"‚ö†Ô∏è –§–∞–π–ª {csv_path} –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü—Ä–æ–ø—É—â–µ–Ω.")
            except Exception as e:
                st.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {csv_path}: {e}. –ü—Ä–æ–ø—É—â–µ–Ω.")
        
        if total_loaded == 0:
            st.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ CSV —Ñ–∞–π–ª–æ–≤. –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.")
            use_csv = False
    
    if not use_csv:
        phishing_urls = [
            "http://secure-login-apple-id.com.verify.account.qwe89.com",
            "http://192.168.1.1/update/bank/login",
            "https://paypal-secure-check.com/signin?user=admin",
            "http://google-drive-secure.login-attempt.net",
            "https://netflix-payment-update.required.com.br",
            "http://sberbank-online-verify.tk",
            "https://vk-admin-login.support-service.ru/auth",
            "http://secure-login.sberbank-verify.tk"
        ]
        legit_urls = [
            "https://www.google.com",
            "https://www.sberbank.ru/ru/person",
            "https://github.com/login",
            "https://en.wikipedia.org/wiki/Machine_learning",
            "https://stackoverflow.com/questions",
            "https://www.apple.com/iphone",
            "https://vk.com",
            "https://habr.com/ru/all/"
        ]

        for url in phishing_urls:
            data.append(extract_features(url))
            labels.append(1) 

        for url in legit_urls:
            data.append(extract_features(url))
            labels.append(0)

    if len(data) == 0:
        st.error("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è!")
        return None

    X = np.array(data)
    y = np.array(labels)

    clf = RandomForestClassifier(n_estimators=100, random_state=42)
    clf.fit(X, y)
    train_score = clf.score(X, y)
    
    return clf, train_score, len(data)

@st.cache_resource
def load_model():
    model_path = 'phishing_model.pkl'
    
    if os.path.exists(model_path):
        try:
            model = joblib.load(model_path)
            st.success("‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å")
            return model, 0.95, 1437096
        except Exception as e:
            st.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å: {e}")
            st.info("üí° –ó–∞–ø—É—Å—Ç–∏—Ç–µ train_model.py –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –Ω–∞ –≤—Å–µ—Ö –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö")
    
    # –ï—Å–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –Ω–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
    st.warning("‚ö†Ô∏è –ü—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç.")
    st.info("üí° –î–ª—è –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –ø–æ–ª–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ (~1.4M –∑–∞–ø–∏—Å–µ–π) –∑–∞–ø—É—Å—Ç–∏—Ç–µ: python3 train_model.py")
    try:
        model, train_accuracy, dataset_size = load_and_train_model(use_csv=False)
        return model, train_accuracy, dataset_size
    except Exception as e:
        st.error(f"Critical System Error: {e}")
        st.stop()

try:
    model, train_accuracy, dataset_size = load_model()
except Exception as e:
    st.error(f"Critical System Error: {e}")
    st.stop()

with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/2092/2092663.png", width=100)
    st.title("CyberShield v1.0")
    st.markdown("---")
    st.markdown("**–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏:**")
    st.code("RandomForest\nScikit-learn\nHeuristic Analysis", language="text")
    st.markdown("---")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –º–æ–¥–µ–ª–∏
    try:
        st.metric("üìä –†–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞", f"{dataset_size:,} URL")
        st.metric("üéØ –¢–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏", f"{train_accuracy:.1%}")
        st.markdown("---")
        st.markdown("**üì¶ –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö:**")
        st.markdown("‚Ä¢ malicious_phish.csv (~651K)")
        st.markdown("‚Ä¢ phishing_site_urls.csv (~549K)")
        st.markdown("‚Ä¢ PhiUSIIL_Phishing_URL_Dataset.csv (~236K)")
        st.markdown("‚Ä¢ legitimate_dataset.csv (~736)")
        st.markdown("‚Ä¢ dataset_example.csv (~11)")
        st.markdown(f"‚Ä¢ **–í—Å–µ–≥–æ: ~1,437,000 URL**")
    except:
        pass
    
    st.markdown("---")
    st.info("‚ÑπÔ∏è –≠—Ç–æ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É URL, —ç–Ω—Ç—Ä–æ–ø–∏—é –¥–æ–º–µ–Ω–∞ –∏ –Ω–∞–ª–∏—á–∏–µ SSL —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–æ–≤ –¥–ª—è –≤—ã—è–≤–ª–µ–Ω–∏—è —É–≥—Ä–æ–∑.")
    st.markdown("**üìà –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ –Ω–∞:**")
    st.markdown("‚Ä¢ ~1.4 –º–∏–ª–ª–∏–æ–Ω–∞ URL –∏–∑ 5 –¥–∞—Ç–∞—Å–µ—Ç–æ–≤")
    st.markdown("‚Ä¢ –õ–µ–≥–∏—Ç–∏–º–Ω—ã–µ: benign, good, label=0")
    st.markdown("‚Ä¢ –§–∏—à–∏–Ω–≥–æ–≤—ã–µ: phishing, malware, defacement, bad, label=1")
    st.markdown("‚Ä¢ 15 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: UsingIP, LongURL, ShortURL, HTTPS, Entropy, Hyphens –∏ –¥—Ä.")

col_main, col_padding = st.columns([3, 1])

with col_main:
    st.title("üõ°Ô∏è Phishing Threat Hunter")
    st.markdown("#### –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –∞–Ω–∞–ª–∏–∑–∞ –≤–µ–±-—Ä–µ—Å—É—Ä—Å–æ–≤")
    
    url_input = st.text_input("–í—Å—Ç–∞–≤—å—Ç–µ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—É—é —Å—Å—ã–ª–∫—É:", placeholder="example.com/login", help="–í–≤–µ–¥–∏—Ç–µ URL —Å http/https –∏–ª–∏ –±–µ–∑ –Ω–∏—Ö")

    if st.button("üöÄ –ó–ê–ü–£–°–¢–ò–¢–¨ –°–ö–ê–ù–ò–†–û–í–ê–ù–ò–ï", type="primary", use_container_width=True):
        if url_input:
            with st.status("üîç –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–∞...", expanded=True) as status:
                # –®–∞–≥ 0: –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–∑–≤–µ—Å—Ç–Ω–æ–≥–æ –¥–æ–º–µ–Ω–∞ (–¥–æ –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏)
                parsed_input = urlparse(url_input if re.match(r'^https?://', url_input, re.IGNORECASE) else f"http://{url_input}")
                hostname_input = parsed_input.netloc if parsed_input.netloc else url_input.split('/')[0]
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –¥–æ–º–µ–Ω –∏–∑–≤–µ—Å—Ç–Ω—ã–º –ª–µ–≥–∏—Ç–∏–º–Ω—ã–º
                is_known_domain = is_known_legitimate_domain(hostname_input)
                
                # –®–∞–≥ 1: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Å–∞–π—Ç–∞
                st.write("üåê –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ —Ä–µ—Å—É—Ä—Å–∞...")
                
                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º URL –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
                test_url = url_input
                if not re.match(r'^https?://', url_input, re.IGNORECASE):
                    test_url = f"https://{url_input}"
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —Å–∞–π—Ç–∞ (–¥–ª—è –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –¥–æ–º–µ–Ω–æ–≤ - –±–æ–ª–µ–µ –º—è–≥–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞)
                is_available, error_msg, status_code = check_site_availability(test_url, timeout=5, is_known_domain=is_known_domain)
                
                if not is_available:
                    # –ï—Å–ª–∏ HTTPS –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–±—É–µ–º HTTP
                    if 'https://' in test_url:
                        http_url = test_url.replace('https://', 'http://')
                        is_available_http, error_msg_http, status_code_http = check_site_availability(http_url, timeout=5, is_known_domain=is_known_domain)
                        if is_available_http:
                            is_available = True
                            error_msg = error_msg_http
                            status_code = status_code_http
                            test_url = http_url
                    
                    if not is_available:
                        status.update(label="–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ", state="error", expanded=False)
                        st.divider()
                        st.markdown(f"""
                        <div class="result-card warning">
                            <h2>‚ö†Ô∏è –†–µ—Å—É—Ä—Å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω</h2>
                            <h3 style="font-size: 2em; margin: 20px 0;">–°–ê–ô–¢ –ù–ï –°–£–©–ï–°–¢–í–£–ï–¢</h3>
                            <p style="font-size: 1.2em; font-weight: bold; color: #f1c40f;">{error_msg}</p>
                            <p style="margin-top: 15px;">üîç –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:</p>
                            <ul style="text-align: left; margin: 15px 0;">
                                <li>–î–æ–º–µ–Ω –Ω–µ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω –∏–ª–∏ —É–¥–∞–ª–µ–Ω</li>
                                <li>–°–∞–π—Ç –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω</li>
                                <li>–û—à–∏–±–∫–∞ DNS (–¥–æ–º–µ–Ω –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç)</li>
                                <li>–°–µ—Ä–≤–µ—Ä –Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç</li>
                            </ul>
                            <p style="margin-top: 15px;">‚ö†Ô∏è <strong>–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:</strong> –ù–µ –ø–µ—Ä–µ—Ö–æ–¥–∏—Ç–µ –ø–æ —ç—Ç–æ–π —Å—Å—ã–ª–∫–µ.</p>
                        </div>
                        """, unsafe_allow_html=True)
                        
                        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≤–µ–∫—Ç–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
                        with st.expander("üî¨ –í–µ–∫—Ç–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–¥–ª—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ–≥–æ —Å–∞–π—Ç–∞)"):
                            try:
                                features_vec = np.array(extract_features(test_url)).reshape(1, -1)
                                feature_names = [
                                    'UsingIP', 'LongURL', 'ShortURL', 'Symbol@', 'Redirecting//', 
                                    'PrefixSuffix-', 'SubDomains', 'HTTPS', 'DomainRegLen', 
                                    'NonStdPort', 'AbnormalURL', 'Entropy', 'SuspiciousWords', 
                                    'KnownDomain', 'Hyphens'
                                ]
                                df = pd.DataFrame(features_vec, columns=feature_names)
                                st.dataframe(df.T, use_container_width=True)
                            except:
                                st.write("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –ø—Ä–∏–∑–Ω–∞–∫–∏")
                        
                        st.stop()
                
                st.write(f"‚úÖ –°–∞–π—Ç –¥–æ—Å—Ç—É–ø–µ–Ω (—Å—Ç–∞—Ç—É—Å: {status_code if status_code else 'OK'})")
                final_url = test_url
                
                # –®–∞–≥ 1: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
                st.write("üì° –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å —Ö–æ—Å—Ç–æ–º...")
                
                if not re.match(r'^https?://', url_input, re.IGNORECASE):
                    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º HTTPS
                    https_works = False
                    try:
                        test_url = f"https://{url_input}"
                        response = requests.head(test_url, timeout=5, allow_redirects=True, verify=True)
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∏–Ω–∞–ª—å–Ω—ã–π URL –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ HTTPS
                        if response.url.startswith('https://'):
                            final_url = test_url
                            status_code = response.status_code
                            https_works = True
                            st.write(f"‚úÖ HTTPS Handshake: OK (Code {status_code})")
                    except requests.exceptions.SSLError:
                        # SSL –æ—à–∏–±–∫–∞ - —Ç–æ—á–Ω–æ –Ω–µ—Ç HTTPS
                        final_url = f"http://{url_input}"
                        st.write("‚ö†Ô∏è SSL –æ—à–∏–±–∫–∞. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è HTTP.")
                    except requests.exceptions.ConnectionError:
                        # –û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è - –ø—Ä–æ–±—É–µ–º HTTP
                        try:
                            http_url = f"http://{url_input}"
                            http_response = requests.head(http_url, timeout=5, allow_redirects=True)
                            final_url = http_url
                            status_code = http_response.status_code
                            st.write(f"‚ö†Ô∏è HTTPS –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. HTTP —Ä–∞–±–æ—Ç–∞–µ—Ç (Code {status_code})")
                        except:
                            final_url = f"http://{url_input}"  # Fallback
                            st.write("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ. –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è HTTP.")
                    except requests.RequestException:
                        # –î—Ä—É–≥–∏–µ –æ—à–∏–±–∫–∏ - –ø—Ä–æ–±—É–µ–º HTTP
                        try:
                            http_url = f"http://{url_input}"
                            http_response = requests.head(http_url, timeout=5, allow_redirects=True)
                            final_url = http_url
                            status_code = http_response.status_code
                            st.write(f"‚ö†Ô∏è HTTPS –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. HTTP —Ä–∞–±–æ—Ç–∞–µ—Ç (Code {status_code})")
                        except:
                            final_url = f"http://{url_input}"  # Fallback
                            st.write("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ. –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è HTTP.")
                    except Exception:
                        # –õ—é–±–∞—è –¥—Ä—É–≥–∞—è –æ—à–∏–±–∫–∞
                        final_url = f"http://{url_input}"
                        st.write("‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏. –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è HTTP.")
                else:
                    final_url = url_input
                    st.write(f"‚ÑπÔ∏è –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–æ—Ç–æ–∫–æ–ª –∏–∑ –∑–∞–ø—Ä–æ—Å–∞: {final_url.split(':')[0]}")

                st.write("üß† –ê–Ω–∞–ª–∏–∑ –≤–µ–∫—Ç–æ—Ä–æ–≤ –∞—Ç–∞–∫–∏ (RandomForest)...")
                features_vec = np.array(extract_features(final_url)).reshape(1, -1)
                probability = model.predict_proba(features_vec)[0][1]
                
                status.update(label="–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ", state="complete", expanded=False)

            # --- –†–ï–ó–£–õ–¨–¢–ê–¢–´ ---
            st.divider()
            
            # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —á–µ—Ä–µ–∑ HTML/CSS –∫–∞—Ä—Ç–æ—á–∫–∏
            if probability > 0.7:
                st.markdown(f"""
                <div class="result-card danger">
                    <h2>üö® –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ —Ñ–∏—à–∏–Ω–≥–æ–≤–∞—è –∞—Ç–∞–∫–∞</h2>
                    <h3 style="font-size: 2.5em; margin: 20px 0;">–£–ì–†–û–ó–ê –û–ë–ù–ê–†–£–ñ–ï–ù–ê</h3>
                    <p style="font-size: 1.3em; font-weight: bold;">–£—Ä–æ–≤–µ–Ω—å –æ–ø–∞—Å–Ω–æ—Å—Ç–∏: {probability:.0%}</p>
                    <p style="margin-top: 15px;">‚ö†Ô∏è –î–∞–Ω–Ω—ã–π —Ä–µ—Å—É—Ä—Å –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω –∫–∞–∫ –º–æ—à–µ–Ω–Ω–∏—á–µ—Å–∫–∏–π.</p>
                    <p>–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ –ø—Ä–µ–∫—Ä–∞—Ç–∏—Ç—å –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ —Å —Å–∞–π—Ç–æ–º.</p>
                </div>
                """, unsafe_allow_html=True)
            elif probability > 0.4:
                st.markdown(f"""
                <div class="result-card suspicious">
                    <h2>‚ö†Ô∏è –ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å</h2>
                    <h3 style="font-size: 2.5em; margin: 20px 0;">–¢–†–ï–ë–£–ï–¢ –í–ù–ò–ú–ê–ù–ò–Ø</h3>
                    <p style="font-size: 1.3em; font-weight: bold;">–£—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞: {probability:.0%}</p>
                    <p style="margin-top: 15px;">–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, —É–∫–∞–∑—ã–≤–∞—é—â–∏–µ –Ω–∞ –≤–æ–∑–º–æ–∂–Ω—É—é —É–≥—Ä–æ–∑—É.</p>
                    <p>–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–¥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ä–µ—Å—É—Ä—Å–∞.</p>
                </div>
                """, unsafe_allow_html=True)
            else:
                st.markdown(f"""
                <div class="result-card safe">
                    <h2>‚úÖ –†–µ—Å—É—Ä—Å –±–µ–∑–æ–ø–∞—Å–µ–Ω</h2>
                    <h3 style="font-size: 2.5em; margin: 20px 0;">–ë–ï–ó–û–ü–ê–°–ù–û</h3>
                    <p style="font-size: 1.3em; font-weight: bold;">–£—Ä–æ–≤–µ–Ω—å —É–≥—Ä–æ–∑—ã: {probability:.0%}</p>
                    <p style="margin-top: 15px;">‚úì –ü—Ä–∏–∑–Ω–∞–∫–æ–≤ —Ñ–∏—à–∏–Ω–≥–∞ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ.</p>
                    <p>–†–µ—Å—É—Ä—Å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∫—Ä–∏—Ç–µ—Ä–∏—è–º –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏.</p>
                </div>
                """, unsafe_allow_html=True)

            # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏
            st.markdown("### üî¨ –í–µ–∫—Ç–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
            df = pd.DataFrame(features_vec, columns=[
                "UsingIP", "LongURL", "ShortURL", "Symbol@", "Redirecting//", 
                "PrefixSuffix-", "SubDomains", "HTTPS", "DomainRegLen", 
                "NonStdPort", "AbnormalURL", "Entropy", "SuspiciousWords", 
                "KnownDomain", "Hyphens"
            ])
            st.dataframe(df, hide_index=True, use_container_width=True)

        else:
            st.warning("–í–≤–µ–¥–∏—Ç–µ URL –¥–ª—è –Ω–∞—á–∞–ª–∞ —Ä–∞–±–æ—Ç—ã.")
